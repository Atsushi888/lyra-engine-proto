from __future__ import annotations
from typing import Any, Dict
import streamlit as st

from components.multi_ai_display_config import MultiAIDisplayConfig


class MultiAIModelViewer:
    """
    MultiAIDisplayConfig ã®æŒ‡ç¤ºã«å¾“ã£ã¦ llm_meta['models'] ã‚’æç”»ã™ã‚‹ãƒ“ãƒ¥ãƒ¼ã€‚
    è¡¨ç¤ºãƒ­ã‚¸ãƒƒã‚¯ã®ã¿ã€‚models ã®æ§‹é€ ã«ã¯å„ªã—ãã€‚
    """

    def __init__(self, config: MultiAIDisplayConfig) -> None:
        self.config = config

    def render(self, models: Dict[str, Any]) -> None:
        st.markdown("#### ğŸ¤– ãƒ¢ãƒ‡ãƒ«å¿œç­”æ¯”è¼ƒ")

        if not isinstance(models, dict) or not models:
            st.caption("ï¼ˆè¡¨ç¤ºå¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“ï¼‰")
            return

        # æ–°ã—ã„ãƒ¢ãƒ‡ãƒ«ã‚’è¨­å®šã«å–ã‚Šè¾¼ã‚“ã§ãŠãï¼ˆæœªç™»éŒ²ãƒ¢ãƒ‡ãƒ«å¯¾ç­–ï¼‰
        self.config.ensure_from_models(models)

        visible = self.config.get_visible_models(models)
        if not visible:
            st.caption("ï¼ˆè¡¨ç¤ºå¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“ï¼‰")
            return

        for key, label in visible:
            info = models.get(key)
            if not isinstance(info, dict):
                st.markdown(f"**{label}** (`{key}`)")
                st.caption("ï¼ˆæƒ…å ±ãŒä¸æ­£ï¼‰")
                st.markdown("---")
                continue

            reply = info.get("reply") or info.get("text") or "ï¼ˆè¿”ä¿¡ãªã—ï¼‰"
            st.markdown(f"**{label}**  (`{key}`)")
            st.write(reply)

            usage = info.get("usage") or info.get("usage_main")
            if isinstance(usage, dict) and usage:
                pt = usage.get("prompt_tokens", "ï¼Ÿ")
                ct = usage.get("completion_tokens", "ï¼Ÿ")
                tt = usage.get("total_tokens", "ï¼Ÿ")
                st.caption(f"tokens: total={tt}, prompt={pt}, completion={ct}")

            st.markdown("---")
