# deliberation/multi_ai_response.py
# ãƒãƒ«ãƒAIã®å¿œç­”è¡¨ç¤º ï¼‹ Judge çµæœè¡¨ç¤ºã®ä¸­æ ¸ã‚¯ãƒ©ã‚¹

from __future__ import annotations

from typing import Any, Dict, Optional

import streamlit as st

from components.multi_ai_display_config import MultiAIDisplayConfig
from components.multi_ai_model_viewer import MultiAIModelViewer
from components.multi_ai_judge_result_view import MultiAIJudgeResultView
from judge_ai import JudgeAI


# ã“ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã§ã€Œå¯©è­°ã«å‚åŠ ã•ã›ã‚‹AIã€ã®ä¸€è¦§
PARTICIPATING_MODELS: Dict[str, str] = {
    "gpt4o": "GPT-4o",
    "hermes": "Hermes",
}


class MultiAIResponse:
    """
    ãƒãƒ«ãƒAIãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚·ã‚¹ãƒ†ãƒ ã®ä¸­æ ¸ã€‚

    ãƒ»ãƒ¢ãƒ‡ãƒ«å¿œç­”æ¯”è¼ƒï¼ˆMultiAIModelViewerï¼‰
    ãƒ»JudgeAI ã«ã‚ˆã‚‹å¯©è­°å®Ÿè¡Œ
    ãƒ»å¯©è­°çµæœè¡¨ç¤ºï¼ˆMultiAIJudgeResultViewï¼‰

    DebugPanel å´ã¯ã€llm_meta ã‚’æ¸¡ã—ã¦ render() ã‚’å‘¼ã¶ã ã‘ã§ã‚ˆã„ã€‚
    """

    def __init__(self, title: str = "ãƒãƒ«ãƒAIãƒ¬ã‚¹ãƒãƒ³ã‚¹") -> None:
        self.title = title

        # è¡¨ç¤ºå¯¾è±¡AIã®è¨­å®š
        display_config = MultiAIDisplayConfig(initial=PARTICIPATING_MODELS)

        # ãƒ“ãƒ¥ãƒ¼ï¼Judge ã®åˆæœŸåŒ–
        self.model_viewer = MultiAIModelViewer(display_config)
        self.judge_view = MultiAIJudgeResultView()
        self.judge_ai = JudgeAI()

    # ------------------------------------------------------------------
    # internal helpers
    # ------------------------------------------------------------------
    def _empty_judge(self, reason: str = "") -> Dict[str, Any]:
        """
        ã‚¨ãƒ©ãƒ¼æ™‚ã‚„æœªåˆ¤å®šæ™‚ã«ä½¿ã† judge ã®ã‚¬ãƒ¯ï¼ˆã²ãªå‹ï¼‰ã€‚
        """
        return {
            "winner": None,
            "score_diff": 0.0,
            "comment": reason,
            "raw": None,
            "pair": None,
        }

    def _ensure_models(self, llm_meta: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """
        llm_meta["models"] ã‚’å–ã‚Šå‡ºã™ã€‚
        å½¢å¼ãŒä¸æ­£ or ç©ºãªã‚‰ None ã‚’è¿”ã™ã€‚
        """
        models = llm_meta.get("models")
        if isinstance(models, dict) and models:
            return models
        return None

    def _ensure_judge(self, llm_meta: Dict[str, Any]) -> Dict[str, Any]:
        """
        llm_meta ã®çŠ¶æ…‹ã‚’è¦‹ã¦ã€å¿…è¦ã§ã‚ã‚Œã° JudgeAI ã‚’å®Ÿè¡Œã—ã€
        å¿…ãš dict å½¢å¼ã® judge ã‚’è¿”ã™ï¼ˆNone ã¯è¿”ã•ãªã„ï¼‰ã€‚
        """
        if not isinstance(llm_meta, dict):
            return self._empty_judge("llm_meta ãŒå­˜åœ¨ã—ã¾ã›ã‚“ã€‚")

        # ã™ã§ã« judge ãŒ dict ã¨ã—ã¦ä¿å­˜ã•ã‚Œã¦ã„ã‚Œã°ãã‚Œã‚’ä½¿ã†
        judge = llm_meta.get("judge")
        if isinstance(judge, dict):
            return judge

        # models ãŒ 2 ã¤æœªæº€ãªã‚‰ãã‚‚ãã‚‚å¯©è­°ä¸èƒ½
        models = self._ensure_models(llm_meta)
        if not isinstance(models, dict) or len(models) < 2:
            return self._empty_judge("æœ‰åŠ¹ãªãƒ¢ãƒ‡ãƒ«æ•°ãŒ 2 æœªæº€ã®ãŸã‚ã€å¯©è­°ã§ãã¾ã›ã‚“ã€‚")

        # ã“ã“ã§ JudgeAI ã‚’å®Ÿè¡Œ
        try:
            judge = self.judge_ai.run(llm_meta)
        except Exception as e:
            return self._empty_judge(f"JudgeAI å®Ÿè¡Œä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")

        if isinstance(judge, dict):
            # å¾Œç¶šã®å†è¡¨ç¤ºã®ãŸã‚ã« llm_meta ã«ã‚‚ä¿å­˜ã—ã¦ãŠã
            llm_meta["judge"] = judge
            return judge

        return self._empty_judge("JudgeAI ãŒä¸æ­£ãªå½¢å¼ã®çµæœã‚’è¿”ã—ã¾ã—ãŸã€‚")

    # ------------------------------------------------------------------
    # public
    # ------------------------------------------------------------------
    def render(self, llm_meta: Optional[Dict[str, Any]]) -> None:
        """
        ãƒãƒ«ãƒAIãƒ¬ã‚¹ãƒãƒ³ã‚¹å…¨ä½“ï¼ˆãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒï¼‹å¯©è­°çµæœï¼‰ã‚’æç”»ã™ã‚‹ã€‚
        DebugPanel ãªã©ã®ä¸Šä½ã‹ã‚‰ã¯ llm_meta ã‚’æ¸¡ã—ã¦å‘¼ã¶ã ã‘ã§ã‚ˆã„ã€‚
        """
        st.markdown(f"### âœ’ï¸ {self.title}")

        if not isinstance(llm_meta, dict) or not llm_meta:
            st.caption("ï¼ˆã¾ã ãƒãƒ«ãƒAIãƒ¬ã‚¹ãƒãƒ³ã‚¹ã¯ã‚ã‚Šã¾ã›ã‚“ï¼‰")
            return

        # ---- ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ ----
        prompt_preview = llm_meta.get("prompt_preview")
        if isinstance(prompt_preview, str) and prompt_preview.strip():
            with st.expander("ğŸ“ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼", expanded=False):
                st.code(prompt_preview, language="text")

        # ---- ãƒ¢ãƒ‡ãƒ«å¿œç­”æ¯”è¼ƒ ----
        models = self._ensure_models(llm_meta)
        if models:
            with st.expander("ğŸ¤ ãƒ¢ãƒ‡ãƒ«å¿œç­”æ¯”è¼ƒ", expanded=True):
                self.model_viewer.render(models)
        else:
            st.caption("ï¼ˆmodels æƒ…å ±ãŒã‚ã‚Šã¾ã›ã‚“ï¼‰")

        # ---- Judge çµæœ ----
        judge = self._ensure_judge(llm_meta)
        with st.expander("âš–ï¸ ãƒãƒ«ãƒAIå¯©è­°çµæœ", expanded=True):
            self.judge_view.render(judge)
