# components/multi_ai_response.py

from __future__ import annotations

from typing import Any, Dict, Optional
import streamlit as st

from components.multi_ai_display_config import MultiAIDisplayConfig
from components.multi_ai_model_viewer import MultiAIModelViewer
from components.multi_ai_judge_result_view import MultiAIJudgeResultView
from deliberation.judge_ai import JudgeAI  # ãƒ‘ã‚¹ã¯ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹æˆã«åˆã‚ã›ã¦èª¿æ•´ã—ã¦ã­


class MultiAIResponse:
    """
    ãƒãƒ«ãƒAIãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚·ã‚¹ãƒ†ãƒ ã®ä¸­æ ¸ã‚¯ãƒ©ã‚¹ã€‚

    ãƒ»è¡¨ç¤ºå¯¾è±¡AIã®è¨­å®šï¼ˆMultiAIDisplayConfigï¼‰
    ãƒ»ãƒ¢ãƒ‡ãƒ«å¿œç­”ãƒ“ãƒ¥ãƒ¼ï¼ˆMultiAIModelViewerï¼‰
    ãƒ»JudgeAI ã«ã‚ˆã‚‹å¯©è­°å®Ÿè¡Œ
    ãƒ»å¯©è­°çµæœãƒ“ãƒ¥ãƒ¼ï¼ˆMultiAIJudgeResultViewï¼‰

    ã‚’ã²ã¨ã¾ã¨ã‚ã«ã—ãŸã€Œè£ç”»é¢ç”¨ã®ãƒãƒ«ãƒAIå¯è¦–åŒ–ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã€ã€‚

    DebugPanel ãªã©ã®ä¸Šä½å´ã¯ã€ã“ã®ã‚¯ãƒ©ã‚¹ã« llm_meta ã‚’æ¸¡ã—ã¦
    render() ã‚’å‘¼ã¶ã ã‘ã§ã‚ˆã„ã€‚
    """

    def __init__(self) -> None:
        # ã“ã“ã§ã€Œã©ã®AIã‚’ã©ã†è¡¨ç¤ºã™ã‚‹ã‹ã€ã‚’å®šç¾©
        display_config = MultiAIDisplayConfig(
            initial={
                "gpt4o": "GPT-4o",
                "hermes": "Hermes",
                # å°†æ¥ã“ã“ã« "claude": "Claude 3" ãªã©ã‚’è¶³ã›ã°æ‹¡å¼µã§ãã‚‹
            }
        )
        self.model_viewer = MultiAIModelViewer(display_config)
        self.judge_view = MultiAIJudgeResultView()
        self.judge_ai = JudgeAI()

    def _ensure_judge(self, llm_meta: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """
        llm_meta ã®çŠ¶æ…‹ã‚’è¦‹ã¦ã€å¿…è¦ã§ã‚ã‚Œã° JudgeAI ã‚’å®Ÿè¡Œã—ã€
        llm_meta["judge"] ã‚’åŸ‹ã‚ã¦è¿”ã™ã€‚
        """
        if not isinstance(llm_meta, dict):
            return None

        judge = llm_meta.get("judge")
        models = llm_meta.get("models")

        if isinstance(judge, dict):
            return judge

        if not isinstance(models, dict) or len(models) < 2:
            return None

        # ã“ã“ã§å®Ÿéš›ã«å¯©è­°ã‚’å®Ÿè¡Œã™ã‚‹
        judge = self.judge_ai.run(llm_meta)
        return judge

    def render(self, llm_meta: Optional[Dict[str, Any]]) -> None:
        """
        ãƒãƒ«ãƒAIãƒ¬ã‚¹ãƒãƒ³ã‚¹å…¨ä½“ã‚’ 1 ãƒ–ãƒ­ãƒƒã‚¯ã¨ã—ã¦æç”»ã™ã‚‹ã€‚

        ä¸Šä½ã‹ã‚‰ã¯ãŸã  llm_meta ã‚’æ¸¡ã—ã¦å‘¼ã³å‡ºã™ã ã‘ã§ã‚ˆã„ã€‚
        """
        if not isinstance(llm_meta, dict) or not llm_meta:
            st.caption("ï¼ˆã¾ã ãƒãƒ«ãƒAIãƒ¬ã‚¹ãƒãƒ³ã‚¹ã¯ã‚ã‚Šã¾ã›ã‚“ï¼‰")
            return

        st.markdown("### ğŸ§ª ãƒãƒ«ãƒAIãƒ¬ã‚¹ãƒãƒ³ã‚¹")

        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼ˆä»»æ„ï¼‰
        prompt_preview = llm_meta.get("prompt_preview")
        if isinstance(prompt_preview, str) and prompt_preview.strip():
            with st.expander("ğŸ“ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼", expanded=False):
                st.code(prompt_preview, language="text")

        # ãƒ¢ãƒ‡ãƒ«å¿œç­”æ¯”è¼ƒ
        models = llm_meta.get("models")
        if isinstance(models, dict) and models:
            with st.expander("ğŸ¤ ãƒ¢ãƒ‡ãƒ«å¿œç­”æ¯”è¼ƒ", expanded=True):
                self.model_viewer.render(models)
        else:
            st.caption("ï¼ˆmodels æƒ…å ±ãŒã‚ã‚Šã¾ã›ã‚“ï¼‰")

        # JudgeAI ã®çµæœ
        judge = self._ensure_judge(llm_meta)
        with st.expander("âš–ï¸ ãƒãƒ«ãƒAIå¯©è­°çµæœ", expanded=True):
            self.judge_view.render(judge)
